{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e257636f-eaf4-4965-9fdc-915945cf5a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jw/_prd4c6n32ggl_4pwszrqnsh0000gn/T/ipykernel_17167/1302931829.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_news['Date'] = pd.to_datetime(df_news['Date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date                                               Text\n",
      "1328    2014-01-01  railcar north dakota crude train crash older l...\n",
      "1329    2014-01-01  skorea dec crude oil import 84 pct yy prelimin...\n",
      "1330    2014-01-01  updat 1iraq oil export averag 2341 mln bpd dec...\n",
      "1331    2014-01-01  iraq oil export averag 2341 mln bpd decemb min...\n",
      "1332    2014-01-01  brazil petrobra start product roncador field p...\n",
      "...            ...                                                ...\n",
      "592597  2024-01-31  us senat committe energi natur resourc full co...\n",
      "592596  2024-01-31  new jersey natur ga compani new jersey natur g...\n",
      "592595  2024-01-31  oil lower us crude stock build score first mon...\n",
      "592665  2024-01-31                    oil price goe brent 8219 barrel\n",
      "592857  2024-01-31  russia novak current oil price adequ reflect m...\n",
      "\n",
      "[592858 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the data\n",
    "df_news = pd.read_csv('/Users/macbook/Documents/PhD_Documents/embedding_methods/news_data/news_total_file.csv')\n",
    "\n",
    "# Drop 'Unnamed: 0' column and remove duplicate values\n",
    "df_news = df_news.drop(columns=['Unnamed: 0'], errors='ignore').drop_duplicates()\n",
    "\n",
    "# Ensure the Date column is in datetime format\n",
    "df_news['Date'] = pd.to_datetime(df_news['Date'], errors='coerce')\n",
    "\n",
    "# Drop rows where the Date conversion failed\n",
    "df_news = df_news.dropna(subset=['Date'])\n",
    "\n",
    "# Sort by Date and format it as YYYY-MM-DD\n",
    "df_news = df_news.sort_values(by='Date')\n",
    "df_news['Date'] = df_news['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Drop duplicates again after formatting Date\n",
    "df_news = df_news.drop_duplicates()\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7257f51-7170-4f05-93ed-ac0b4aaa1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 6 parts (if needed)\n",
    "split_point = len(df_news) // 6\n",
    "df_news_1 = df_news.iloc[:split_point]\n",
    "df_news_2 = df_news.iloc[split_point:2*split_point]\n",
    "df_news_3 = df_news.iloc[2*split_point:3*split_point]\n",
    "df_news_4 = df_news.iloc[3*split_point:4*split_point]\n",
    "df_news_5 = df_news.iloc[4*split_point:5*split_point]\n",
    "df_news_6 = df_news.iloc[5*split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb22c79c-f02a-4e07-8423-2f1bd521d645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/macbook/anaconda3/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <9A4710B9-0DA3-36BB-9129-645F282E64B2> /Users/macbook/anaconda3/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <ECC148AF-20FF-3EEE-BC75-4DD3E7455393> /Users/macbook/anaconda3/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/macbook/anaconda3/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/macbook/anaconda3/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "Processing Text: 100%|████████████████| 592858/592858 [7:12:31<00:00, 22.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Check if GPU is available and move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define a function to get embeddings with different pooling strategies\n",
    "def get_embedding(text, strategy=\"cls\"):\n",
    "    tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    token_embeddings = outputs.last_hidden_state\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    \n",
    "    if strategy == \"cls\":\n",
    "        # [CLS] token embedding\n",
    "        cls_embedding = token_embeddings[:, 0, :]\n",
    "        return cls_embedding.squeeze().tolist()\n",
    "    elif strategy == \"mean\":\n",
    "        # Mean pooling\n",
    "        mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "        token_embeddings_masked = token_embeddings.masked_fill(mask_expanded == 0, 0)\n",
    "        sum_embeddings = torch.sum(token_embeddings_masked, dim=1)\n",
    "        sum_mask = mask_expanded.sum(dim=1)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings.squeeze().tolist()\n",
    "    elif strategy == \"max\":\n",
    "        # Max pooling\n",
    "        mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "        token_embeddings_masked = token_embeddings.masked_fill(mask_expanded == 0, -1e9)\n",
    "        max_embeddings = torch.max(token_embeddings_masked, dim=1).values\n",
    "        return max_embeddings.squeeze().tolist()\n",
    "    elif strategy == \"sum\":\n",
    "        # Sum pooling\n",
    "        mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "        token_embeddings_masked = token_embeddings.masked_fill(mask_expanded == 0, 0)\n",
    "        sum_embeddings = torch.sum(token_embeddings_masked, dim=1)\n",
    "        return sum_embeddings.squeeze().tolist()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown pooling strategy: {strategy}\")\n",
    "\n",
    "# Apply the embedding function to the 6th part of the dataframe\n",
    "pooling_strategy = \"mean\"  # Change to \"cls\", \"max\", or \"sum\" for other strategies\n",
    "df_news['embeddings'] = [get_embedding(text, strategy=pooling_strategy) for text in tqdm(df_news['Text'], desc=\"Processing Text\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23502745-4b49-4cb2-bacf-abde12431cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>railcar north dakota crude train crash older l...</td>\n",
       "      <td>[0.28228703141212463, -0.3216705620288849, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>skorea dec crude oil import 84 pct yy prelimin...</td>\n",
       "      <td>[-0.11626404523849487, -0.01936078630387783, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>updat 1iraq oil export averag 2341 mln bpd dec...</td>\n",
       "      <td>[-0.24160714447498322, -0.2372460812330246, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>iraq oil export averag 2341 mln bpd decemb min...</td>\n",
       "      <td>[-0.19026753306388855, -0.043890636414289474, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>brazil petrobra start product roncador field p...</td>\n",
       "      <td>[0.03664577379822731, -0.08797629922628403, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592597</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>us senat committe energi natur resourc full co...</td>\n",
       "      <td>[-0.090078204870224, -0.0732942745089531, 0.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592596</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>new jersey natur ga compani new jersey natur g...</td>\n",
       "      <td>[-0.03526687994599342, -0.4973338842391968, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592595</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>oil lower us crude stock build score first mon...</td>\n",
       "      <td>[0.0017135110683739185, -0.4250740110874176, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592665</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>oil price goe brent 8219 barrel</td>\n",
       "      <td>[-0.07852102816104889, -0.4520896077156067, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592857</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>russia novak current oil price adequ reflect m...</td>\n",
       "      <td>[-0.364582359790802, -0.1083567664027214, 0.16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>592858 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date                                               Text  \\\n",
       "1328    2014-01-01  railcar north dakota crude train crash older l...   \n",
       "1329    2014-01-01  skorea dec crude oil import 84 pct yy prelimin...   \n",
       "1330    2014-01-01  updat 1iraq oil export averag 2341 mln bpd dec...   \n",
       "1331    2014-01-01  iraq oil export averag 2341 mln bpd decemb min...   \n",
       "1332    2014-01-01  brazil petrobra start product roncador field p...   \n",
       "...            ...                                                ...   \n",
       "592597  2024-01-31  us senat committe energi natur resourc full co...   \n",
       "592596  2024-01-31  new jersey natur ga compani new jersey natur g...   \n",
       "592595  2024-01-31  oil lower us crude stock build score first mon...   \n",
       "592665  2024-01-31                    oil price goe brent 8219 barrel   \n",
       "592857  2024-01-31  russia novak current oil price adequ reflect m...   \n",
       "\n",
       "                                               embeddings  \n",
       "1328    [0.28228703141212463, -0.3216705620288849, -0....  \n",
       "1329    [-0.11626404523849487, -0.01936078630387783, 0...  \n",
       "1330    [-0.24160714447498322, -0.2372460812330246, 0....  \n",
       "1331    [-0.19026753306388855, -0.043890636414289474, ...  \n",
       "1332    [0.03664577379822731, -0.08797629922628403, 0....  \n",
       "...                                                   ...  \n",
       "592597  [-0.090078204870224, -0.0732942745089531, 0.33...  \n",
       "592596  [-0.03526687994599342, -0.4973338842391968, 0....  \n",
       "592595  [0.0017135110683739185, -0.4250740110874176, 0...  \n",
       "592665  [-0.07852102816104889, -0.4520896077156067, 0....  \n",
       "592857  [-0.364582359790802, -0.1083567664027214, 0.16...  \n",
       "\n",
       "[592858 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d6947c3-a959-4435-af0d-0ffa450eaf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date                                               Text  \\\n",
      "1328    2014-01-01  railcar north dakota crude train crash older l...   \n",
      "1329    2014-01-01  skorea dec crude oil import 84 pct yy prelimin...   \n",
      "1330    2014-01-01  updat 1iraq oil export averag 2341 mln bpd dec...   \n",
      "1331    2014-01-01  iraq oil export averag 2341 mln bpd decemb min...   \n",
      "1332    2014-01-01  brazil petrobra start product roncador field p...   \n",
      "...            ...                                                ...   \n",
      "592597  2024-01-31  us senat committe energi natur resourc full co...   \n",
      "592596  2024-01-31  new jersey natur ga compani new jersey natur g...   \n",
      "592595  2024-01-31  oil lower us crude stock build score first mon...   \n",
      "592665  2024-01-31                    oil price goe brent 8219 barrel   \n",
      "592857  2024-01-31  russia novak current oil price adequ reflect m...   \n",
      "\n",
      "        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "1328     0.282287  -0.321671  -0.167749   0.193705   0.301912  -0.177227   \n",
      "1329    -0.116264  -0.019361   0.447963   0.021400   0.516291   0.177048   \n",
      "1330    -0.241607  -0.237246   0.233642   0.050318   0.417027   0.127496   \n",
      "1331    -0.190268  -0.043891  -0.055873  -0.057461   0.319541  -0.004950   \n",
      "1332     0.036646  -0.087976   0.025121   0.146535   0.481841  -0.070384   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "592597  -0.090078  -0.073294   0.333889   0.031942   0.414264  -0.032835   \n",
      "592596  -0.035267  -0.497334   0.145453  -0.013438   0.511603  -0.175528   \n",
      "592595   0.001714  -0.425074   0.387173   0.053179   0.471982   0.004098   \n",
      "592665  -0.078521  -0.452090   0.037148  -0.149793   0.193324  -0.055115   \n",
      "592857  -0.364582  -0.108357   0.164264  -0.002496   0.323703   0.055831   \n",
      "\n",
      "        feature_6  feature_7  ...  feature_758  feature_759  feature_760  \\\n",
      "1328     0.062228   0.282343  ...     0.115310     0.163864    -0.082785   \n",
      "1329    -0.154638   0.397028  ...     0.276808     0.088515    -0.077743   \n",
      "1330    -0.289903   0.159794  ...     0.026363     0.043459     0.026556   \n",
      "1331    -0.222740   0.168039  ...     0.034387     0.075978     0.068935   \n",
      "1332    -0.245081   0.387616  ...     0.086380    -0.035325    -0.046528   \n",
      "...           ...        ...  ...          ...          ...          ...   \n",
      "592597  -0.164795   0.106135  ...     0.097857    -0.016532    -0.065543   \n",
      "592596  -0.276003   0.193789  ...     0.048142    -0.063474    -0.137483   \n",
      "592595  -0.110624   0.136792  ...     0.380806    -0.083659     0.043275   \n",
      "592665   0.067539   0.536306  ...     0.076402    -0.095590     0.387111   \n",
      "592857  -0.205794   0.280168  ...     0.283818    -0.310096    -0.017786   \n",
      "\n",
      "        feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
      "1328      -0.271231     0.317921    -0.314026     0.104388    -0.087685   \n",
      "1329      -0.190895     0.317944    -0.286780    -0.159502    -0.032912   \n",
      "1330      -0.137092     0.471577    -0.119538    -0.013889    -0.151818   \n",
      "1331      -0.194267     0.499694    -0.230469    -0.142324    -0.253629   \n",
      "1332      -0.063975     0.316249    -0.091753    -0.161070    -0.398803   \n",
      "...             ...          ...          ...          ...          ...   \n",
      "592597    -0.051923     0.017362     0.021168    -0.164931    -0.126285   \n",
      "592596    -0.256648    -0.203951    -0.183667    -0.189609    -0.060480   \n",
      "592595    -0.213582     0.443701     0.004730    -0.145373    -0.237623   \n",
      "592665    -0.485210     0.266513    -0.128941     0.122996    -0.316074   \n",
      "592857    -0.119543     0.011456    -0.420821     0.209976    -0.341677   \n",
      "\n",
      "        feature_766  feature_767  \n",
      "1328       0.082011    -0.176243  \n",
      "1329       0.141159    -0.009808  \n",
      "1330       0.088531     0.010692  \n",
      "1331      -0.066731     0.007819  \n",
      "1332      -0.000908     0.050837  \n",
      "...             ...          ...  \n",
      "592597    -0.083056    -0.035287  \n",
      "592596    -0.096166     0.223017  \n",
      "592595     0.200950    -0.117926  \n",
      "592665     0.384331    -0.191162  \n",
      "592857     0.295632     0.096031  \n",
      "\n",
      "[592858 rows x 770 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split the embeddings into separate columns and concatenate with the original dataframe\n",
    "final_df = pd.concat(\n",
    "    [df_news.drop(columns=['embeddings']),\n",
    "     pd.DataFrame(df_news['embeddings'].values.tolist(), index=df_news.index)\n",
    "      .rename(columns=lambda i: f'feature_{i}')],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display the final dataframe\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd238b79-185b-4288-a88c-b344c1eb00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('Bert_total_embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3290d15d-2872-4f52-bc07-a97c80eacd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "Date                                                                           \n",
      "2014-01-01  -0.043475  -0.164988   0.183225   0.056277   0.375607  -0.029788   \n",
      "2014-01-02  -0.035107  -0.170385   0.150354   0.019579   0.319369  -0.060770   \n",
      "2014-01-03  -0.047644  -0.170381   0.165911   0.066791   0.340221  -0.021383   \n",
      "2014-01-04   0.032417  -0.075082  -0.047487  -0.078541   0.318565  -0.087398   \n",
      "2014-01-05   0.007307  -0.161989   0.147542  -0.184680   0.218439  -0.140416   \n",
      "...               ...        ...        ...        ...        ...        ...   \n",
      "2024-01-27  -0.084876  -0.236796   0.185873  -0.025501   0.356431  -0.021305   \n",
      "2024-01-28   0.009375  -0.175774   0.186066  -0.032545   0.344828  -0.078430   \n",
      "2024-01-29  -0.046906  -0.213831   0.225373   0.012302   0.337351  -0.050423   \n",
      "2024-01-30  -0.036904  -0.209402   0.223687   0.039722   0.343290  -0.059763   \n",
      "2024-01-31  -0.085764  -0.225207   0.244442   0.006394   0.327652  -0.058389   \n",
      "\n",
      "            feature_6  feature_7  feature_8  feature_9  ...  feature_758  \\\n",
      "Date                                                    ...                \n",
      "2014-01-01  -0.072864   0.263491  -0.041225  -0.101866  ...     0.094211   \n",
      "2014-01-02  -0.127465   0.287525  -0.007526  -0.146524  ...     0.170944   \n",
      "2014-01-03  -0.115622   0.243681   0.010908  -0.183344  ...     0.137593   \n",
      "2014-01-04  -0.136170   0.240086   0.045269  -0.274565  ...     0.223680   \n",
      "2014-01-05  -0.042000   0.219128   0.011946  -0.108504  ...     0.090056   \n",
      "...               ...        ...        ...        ...  ...          ...   \n",
      "2024-01-27  -0.100243   0.292478  -0.076301  -0.185847  ...     0.121968   \n",
      "2024-01-28  -0.080421   0.210191   0.026969  -0.174880  ...     0.088565   \n",
      "2024-01-29  -0.120861   0.284553  -0.009441  -0.194031  ...     0.149865   \n",
      "2024-01-30  -0.149642   0.236881   0.002907  -0.155221  ...     0.143595   \n",
      "2024-01-31  -0.108200   0.248001   0.023615  -0.153833  ...     0.188345   \n",
      "\n",
      "            feature_759  feature_760  feature_761  feature_762  feature_763  \\\n",
      "Date                                                                          \n",
      "2014-01-01     0.071711    -0.034948    -0.180185     0.339132    -0.153768   \n",
      "2014-01-02    -0.044533    -0.003720    -0.185885     0.234975    -0.138089   \n",
      "2014-01-03    -0.013697    -0.018992    -0.143535     0.203654    -0.117194   \n",
      "2014-01-04    -0.122747     0.103169    -0.132038     0.325845    -0.213964   \n",
      "2014-01-05     0.054774    -0.028078    -0.215831     0.207093    -0.190729   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2024-01-27    -0.087832     0.056597    -0.124212     0.216460    -0.118995   \n",
      "2024-01-28    -0.003725     0.047658    -0.212198     0.192936    -0.085001   \n",
      "2024-01-29    -0.049474     0.022057    -0.185159     0.232863    -0.085582   \n",
      "2024-01-30    -0.029469     0.014690    -0.196236     0.237839    -0.092767   \n",
      "2024-01-31    -0.014167     0.011707    -0.207997     0.201021    -0.109973   \n",
      "\n",
      "            feature_764  feature_765  feature_766  feature_767  \n",
      "Date                                                            \n",
      "2014-01-01    -0.096646    -0.136302     0.014967    -0.025114  \n",
      "2014-01-02    -0.075009    -0.168460     0.061644    -0.097534  \n",
      "2014-01-03    -0.126461    -0.123451     0.061152    -0.028146  \n",
      "2014-01-04    -0.099896    -0.319039     0.112410    -0.153117  \n",
      "2014-01-05    -0.125798    -0.226082    -0.021526    -0.172561  \n",
      "...                 ...          ...          ...          ...  \n",
      "2024-01-27    -0.117143    -0.203489     0.051715    -0.030031  \n",
      "2024-01-28    -0.174627    -0.169945     0.007686    -0.063681  \n",
      "2024-01-29    -0.119075    -0.185043     0.043983    -0.070524  \n",
      "2024-01-30    -0.137658    -0.172941     0.050096    -0.062844  \n",
      "2024-01-31    -0.139083    -0.176177     0.077498    -0.047044  \n",
      "\n",
      "[3683 rows x 768 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'Text' column\n",
    "final_df = final_df.drop(columns=['Text'])\n",
    "\n",
    "# Compute the mean of features grouped by the 'Date' column\n",
    "mean_grouped_df = final_df.groupby('Date').mean()\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(mean_grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d2282f2-d114-478d-90f0-8087e9a6598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_grouped_df.to_csv('BERT_mean_embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df75dc0-2cf1-4c4d-b15c-6902437b736d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
